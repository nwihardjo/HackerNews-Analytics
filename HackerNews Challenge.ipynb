{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HackerNews data analysis challenge with Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will analyse a dataset of (almost) all submitted HackerNews posts with Spark. Let's start by importing some of the libraries you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[*] appName=pyspark-shell>\n",
      "Ready to go!\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "print(sc)\n",
    "print(\"Ready to go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file has one JSON entry per line. In order to make accessing it easier, first turn each entry as a dictionary and use `persist()` to cache the resulting RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_json = sc.textFile(\"HNStories.json\")\n",
    "dataset = dataset_json.map(lambda x: json.loads(x))\n",
    "dataset.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, Spark has many helper functions on top of the ones we have studied which you will find useful. You can view them at [http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with some initial analysis. \n",
    "* How many elements are in your datasets?\n",
    "* What does the first element look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'author': 'TuxLyn',\n",
       "  'created_at': '2014-05-29T08:25:40Z',\n",
       "  'created_at_i': 1401351940,\n",
       "  'num_comments': 0,\n",
       "  'objectID': '7815290',\n",
       "  'points': 1,\n",
       "  'title': 'DuckDuckGo Settings',\n",
       "  'url': 'https://duckduckgo.com/settings'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in each data 8\n"
     ]
    }
   ],
   "source": [
    "print('Number of elements in each data', len(dataset.take(1)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element is a dictionary of attributes and their values for a post. Can you find the set of all attributes used throughout the RDD? The function `dictionary.keys()` gives you the list of attributes of a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['author', 'created_at', 'created_at_i', 'num_comments', 'objectID', 'points', 'title', 'url'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['created_at', 'points', 'created_at_i', 'story_text', 'objectID', 'title', 'author', 'url', 'story_id', 'num_comments']\n"
     ]
    }
   ],
   "source": [
    "elements = dataset.flatMap(lambda x: x.keys()).distinct().collect()\n",
    "print(elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are more attributes than just the one used in the first element. the function `compare_elems` below returns `True` if two elements have exactly the same set of attributes. Can you use it to count the number of elements which have the same set of attributes as the first element?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns true if two elements have the same schema\n",
    "#first, second is a list\n",
    "\n",
    "def compare_elems(first, second):\n",
    "    if len(first) != len(second):\n",
    "        return False\n",
    "    for key in first:\n",
    "        if key not in second:\n",
    "            return False    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements which have the same set of attributes as the first element is:  1145245\n"
     ]
    }
   ],
   "source": [
    "first = dataset.take(1)\n",
    "compared_data = dataset.map(lambda x: compare_elems(first[0].keys(), x.keys()))\n",
    "print('Number of elements which have the same set of attributes as the first element is: ',\n",
    "      compared_data.filter(lambda x: x==True).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the vast majority of elements hold the same structure. In order to make this analysis easier, redefine `dataset` to only have elements which hold this structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of elements in new dataset:  1145245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'author': 'TuxLyn',\n",
       "  'created_at': '2014-05-29T08:25:40Z',\n",
       "  'created_at_i': 1401351940,\n",
       "  'num_comments': 0,\n",
       "  'objectID': '7815290',\n",
       "  'points': 1,\n",
       "  'title': 'DuckDuckGo Settings',\n",
       "  'url': 'https://duckduckgo.com/settings'},\n",
       " {'author': 'Leynos',\n",
       "  'created_at': '2014-05-29T08:23:46Z',\n",
       "  'created_at_i': 1401351826,\n",
       "  'num_comments': 0,\n",
       "  'objectID': '7815285',\n",
       "  'points': 1,\n",
       "  'title': 'Making Twitter Easier to Use',\n",
       "  'url': 'http://bits.blogs.nytimes.com/2014/05/28/making-twitter-easier-to-use/'},\n",
       " {'author': 'darrhiggs',\n",
       "  'created_at': '2014-05-29T08:21:56Z',\n",
       "  'created_at_i': 1401351716,\n",
       "  'num_comments': 0,\n",
       "  'objectID': '7815279',\n",
       "  'points': 2,\n",
       "  'title': 'London refers Uber app row to High Court',\n",
       "  'url': 'http://www.bbc.co.uk/news/technology-27617079'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = dataset.filter(lambda x: compare_elems(first[0].keys(), x.keys()))\n",
    "print('The number of elements in new dataset: ', new_dataset.count())\n",
    "new_dataset.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the following tasks are optional, if you want to analyse the dataset in your own way using Spark feel free to do so! The tasks are there as a guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: How many posts through time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The field `created_at_i` is very useful, it gives you a UNIX timestamp of the time at which the file was created. The following function lets you extract a time from a timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_time(timestamp):\n",
    "    return dt.fromtimestamp(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the minimum and maximum timestamps in the RDD and call them `min_time` and `max_time`. These correspond to the first and last post, when did they occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max(x, y):\n",
    "    if x['created_at_i'] > y['created_at_i']:\n",
    "        return x\n",
    "    else:\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'TuxLyn',\n",
       " 'created_at': '2014-05-29T08:25:40Z',\n",
       " 'created_at_i': 1401351940,\n",
       " 'num_comments': 0,\n",
       " 'objectID': '7815290',\n",
       " 'points': 1,\n",
       " 'title': 'DuckDuckGo Settings',\n",
       " 'url': 'https://duckduckgo.com/settings'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnew_dataset.reduce(lambda x, y: max(x, y))['created_at_i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(min_time)\n",
    "print(max_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets analyse how many elements through time. The following function assigns a record to one of 200 \"buckets\" of time. Use it to count the number of elements that fall within each bucket and call the result `bucket_rdd`. The result should be such that `buckets` below generates the corresponding output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interval = (max_time - min_time + 1) / 200.0\n",
    "\n",
    "def get_bucket(rec):\n",
    "    return int((rec['created_at_i'] - min_time) / interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this to test your result\n",
    "buckets = sorted(buckets_rdd.collect())\n",
    "print(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is approximately the desired output\n",
    "buckets = sorted(buckets_rdd.collect())\n",
    "print(buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use this to plot the number of submitted posts over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bs = [dt.fromtimestamp(x[0]*interval + min_time) for x in buckets]\n",
    "ts = [x[1] for x in buckets]\n",
    "plt.plot(bs, ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following function gets the hour of the day at which a post was submitted. Use it to find the number of posts submitted at each hour of the day. The value of `hours_buckets` should match the one printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hour(rec):\n",
    "    t = dt.fromtimestamp(rec['created_at_i'])\n",
    "    return t.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hours_buckets = sorted(hours_buckets_rdd.collect())\n",
    "print(hours_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hours_buckets = sorted(hours_buckets_rdd.collect())\n",
    "print(hours_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hrs = [x[0] for x in hours_buckets]\n",
    "sz = [x[1] for x in hours_buckets]\n",
    "plt.plot(hrs, sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of points scored by a post is under the attribute `points`. Use it to compute the average score received by submissions for each hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#what the data looks like\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_per_hour = sorted(scores_per_hour_rdd.collect())\n",
    "print(scores_per_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_per_hour = sorted(scores_per_hour_rdd.collect())\n",
    "print(scores_per_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hrs = [x[0] for x in scores_per_hour]\n",
    "sz = [x[1] for x in scores_per_hour]\n",
    "plt.plot(hrs, sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be more useful to look at sucessful posts that get over 200 points. Find the proportion of posts that get above 200 points per hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_per_hour = sorted(prop_per_hour_rdd.collect())\n",
    "print(prop_per_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_per_hour = sorted(prop_per_hour_rdd.collect())\n",
    "print(prop_per_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hrs = [x[0] for x in prop_per_hour]\n",
    "sz = [x[1] for x in prop_per_hour]\n",
    "plt.plot(hrs, sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function lists the word in the title. Use it to count the number of words in the title of each post, and look at the proportion of successful posts for each title length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def get_words(line):\n",
    "    return re.compile('\\w+').findall(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_per_title_length = sorted(prop_per_title_length_rdd.collect())\n",
    "print(prop_per_title_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_per_title_length = sorted(prop_per_title_length_rdd.collect())\n",
    "print(prop_per_title_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hrs = [x[0] for x in prop_per_title_length]\n",
    "sz = [x[1] for x in prop_per_title_length]\n",
    "plt.plot(hrs, sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare this with the distribution of number of words. Count for each title length the number of submissions with that length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submissions_per_length = sorted(submissions_per_length_rdd.collect())\n",
    "print(submissions_per_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submissions_per_length = sorted(submissions_per_length_rdd.collect())\n",
    "print(submissions_per_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hrs = [x[0] for x in submissions_per_length]\n",
    "sz = [x[1] for x in submissions_per_length]\n",
    "plt.plot(hrs, sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like most people are getting it wrong!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For this task, you will need a new function: `takeOrdered()`. Like `take()` it collects elements from an RDD. However, it can be applied the smalles elements. For example, `takeOrdered(10)` returns the 10 smallest elements. Furthermore, you can pass it a function to specify the way in which the elements should be ordered. For example, `takeOrdered(10, lambda x: -x)` will return the 10 largest elements.\n",
    "\n",
    "The function below extracts the url domain out of a record. Use it to count the number of distinct domains posted to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from urlparse import urlparse\n",
    "def get_domain(rec):\n",
    "    url = urlparse(rec['url']).netloc\n",
    "    if url[0:4] == 'www.':\n",
    "        return url[4:]\n",
    "    else:\n",
    "        return url\n",
    "print(get_domain(dataset.take(1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `takeOrdered()` find the 25 most popular domains posted to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(top25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(top25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = np.arange(25)\n",
    "labels = [x[0] for x in top25]\n",
    "counts = np.array([x[1] for x in top25]) * 100.0/dataset.count()\n",
    "plt.xticks(index,labels, rotation='vertical')\n",
    "plt.bar(index, counts, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an pair RDD with 26 elements mapping each of these 25 popular domains with the average score received by the corresponding submissions as well as an `other` field for all submissions to other domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_to_domain(rec):\n",
    "    domain = get_domain(rec)\n",
    "    if domain in dict(top25):\n",
    "        return domain\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain_av_score = domain_av_score_rdd.collect()\n",
    "print(domain_av_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain_av_score = domain_av_score_rdd.collect()\n",
    "print(domain_av_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index26 = np.arange(26)\n",
    "labels = [x[0] for x in top25]\n",
    "labels.append('other')\n",
    "vals = np.array([dict(domain_av_score)[x] for x in labels])\n",
    "plt.xticks(index26, labels, rotation='vertical')\n",
    "plt.bar(index26, vals, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the proportion of successes for each domain (over 200 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain_prop = domain_prop_rdd.collect()\n",
    "print(domain_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain_prop = domain_prop_rdd.collect()\n",
    "print(domain_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index26 = np.arange(26)\n",
    "labels = [x[0] for x in top25]\n",
    "labels.append('other')\n",
    "vals = np.array([dict(domain_prop)[x] for x in labels])\n",
    "plt.xticks(index26, labels, rotation='vertical')\n",
    "plt.bar(index26, vals, 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
